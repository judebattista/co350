The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation.

Brundage, M., Avin, S., Clark, J., Toner, H., Eckersley, P., Garfinkel, B., ... Amodei, D. (2017). The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation. Retrieved from https://arxiv.org/ftp/arxiv/papers/1802/1802.07228.pdf

The nature of Artificial Intelligence makes it inherently dangerous. Looking a mere five years into the future we can envision security threats along the digital, physical, and political axes. Because AI is designed as a problem solving tool, it is an inherently dual-use technology, employable towards both beneficent and harmful ends. In order for an AI solution to be effective, it should be efficient and scalable. Further it likely exceeds human capabilities or it would not be employed. These requirements are analagous to those for an effective battlefield weapon system. Since AIs are fundamentally software, they are much more portable than hardware weapon systems, making it impossible to control their distribution over any but the smallest time scales. 

With human-plus capabilities, AI systems are natural force multipliers for extant threats. Even a simple multisystem management intelligence could be used to upscale independent drone attacks into an exponentially more dangerous swarm attack. As AI develops, its transformative nature imples that it will produce new threats, many of which will be entirely unpredictable. We have already seen Deepfake technology produce video forgeries of unprecedented quality, threatening both digital and political security. Similarly, AI will transform the character of pre-existing threats. Currently, attackers can either employ targeted phishing attempts or deploy them widely, but an AI system could theoretically combine both properties in a single attack.

In order to avert catastrophe the authors recommend a four-fold approach. Policymakers and technologists must collaborate to design informed, responsible policies on AI creation and regulation. AI creators must consider the implications of of the dual-use nature of their work. While the nature of AI precludes the elimination of such risks, we can at least mitigate the worst cases and provide some safeguards. Thirdly, this consideration must lead to the creation and implementation of industry-wide best practices. Finally, we need to include as many viewpoints as possible in discussing these challenges. While depth of knowledge is essential for threat assessment, the broad scope of AI capabilities requires us to also emphasisize a collective breadth of knowledge to ensure that we do not overlook or dismiss potential threat vectors.